{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score compression of resacled data (subsamples) with susequent neural density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "# load your pydelfi version here (not necessary to include path if you have pip installed)\n",
    "sys.path.append(\"/home/nessa/Documents/Projects/pydelfi/\") \n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import compression.score.score as score\n",
    "import distributions.priors as priors\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (note that order of params is not the same as data_sim)\n",
    "data_scaled        = np.load('./data/data_scaled.npy')\n",
    "data_scaled_full   = np.load('./data/data_scaled.full.npy')\n",
    "data_scaled_cosmos = np.load('./data/params_conc.npy')\n",
    "data_scaled_cosmos_full = np.load('./data/params_conc.full.npy')\n",
    "\n",
    "covariance = np.load('./data/covariance.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10100, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.3 2.1]\n"
     ]
    }
   ],
   "source": [
    "# fiducial parameters (for compression)\n",
    "index = 51\n",
    "index_0 = 53\n",
    "theta_fiducial = data_scaled_cosmos_full[index]\n",
    "print(theta_fiducial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_cov = data_scaled_cosmos_full[index_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance from covariance sims\n",
    "Cov_Inv = np.linalg.inv(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian process interpolation of (precompressed) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nessa/miniconda2/envs/py3torch/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:480: ConvergenceWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.47331807e+06, -3.50756860e+00]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 70, 'nit': 25, 'warnflag': 2}\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "\n",
    "kernel = C(1.0, (1e-4, 1e4)) * RBF(1, (1e-4, 1e4))\n",
    "#Instanciate a Gaussian Process model\n",
    "gp     = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "\n",
    "#  fit the Gaussian process model on the mean of the (precompressed) data for each comsologyy\n",
    "\n",
    "\n",
    "# fit \n",
    "gp.fit(data_scaled_cosmos_full,data_scaled_full)\n",
    "\n",
    "#use the GP prediction to build the model\n",
    "def fitGP(theta):\n",
    "    pred, stdev = gp.predict(np.array(theta).reshape(1,3),return_std=True)\n",
    "    return pred.T\n",
    "\n",
    "# compute derivative of mean at fiducial model with finite differencing\n",
    "\n",
    "h      = 0.01\n",
    "\n",
    "theta1 = np.asarray([theta_fiducial[0]*(1+h), theta_fiducial[1],theta_fiducial[2]])\n",
    "theta1_= np.asarray([theta_fiducial[0]*(1-h), theta_fiducial[1],theta_fiducial[2]])\n",
    "\n",
    "theta2 = np.asarray([theta_fiducial[0], theta_fiducial[1]*(1+h),theta_fiducial[2]])\n",
    "theta2_= np.asarray([theta_fiducial[0], theta_fiducial[1]*(1-h),theta_fiducial[2]])\n",
    "\n",
    "theta3 = np.asarray([theta_fiducial[0], theta_fiducial[1],theta_fiducial[2]*(1+h)])\n",
    "theta3_= np.asarray([theta_fiducial[0], theta_fiducial[1],theta_fiducial[2]*(1-h)])\n",
    "\n",
    "dmudt1 = (fitGP(theta1)-fitGP(theta1_))/(theta1-theta1_)[0]\n",
    "dmudt2 = (fitGP(theta2)-fitGP(theta2_))/(theta2-theta2_)[1]\n",
    "dmudt3 = (fitGP(theta3)-fitGP(theta3_))/(theta3-theta3_)[2]\n",
    "\n",
    "# derivative\n",
    "dmudt = np.hstack((dmudt1,dmudt2,dmudt3)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nessa/miniconda2/envs/py3torch/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:357: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    }
   ],
   "source": [
    "# set up scrore compression\n",
    "mu             = fitGP(theta_fiducial)[:,0]\n",
    "Cinv           = Cov_Inv\n",
    "\n",
    "\n",
    "Compressor     = score.Gaussian(len(mu), theta_fiducial, mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "Compressor.compute_fisher()\n",
    "Finv           = Compressor.Finv\n",
    "\n",
    "def compressor(d, compressor_args):\n",
    "    return Compressor.scoreMLE(d)\n",
    "compressor_args=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.72682977e+02 -4.71195347e+02 -6.42995065e+02 -9.62919499e+02\n",
      "  -1.41649948e+03 -1.18779533e+03 -1.00374627e+03 -1.48568129e+03\n",
      "  -1.37401463e+03 -1.26440719e+03 -6.98956597e+01 -4.93843221e+01\n",
      "   1.17071695e+02  1.51716015e+03  1.04991881e+03  4.68832532e+03\n",
      "   4.20764209e+03  4.96445396e+03  4.17861292e+03  4.16340762e+03\n",
      "   5.50731383e+03  4.62079307e+03  5.06053439e+03  3.59664099e+03\n",
      "   3.05866137e+03  2.77886747e+03  3.39388673e+03  8.28776873e+02\n",
      "   2.88783664e+03  8.83308137e+02  1.67745933e+02  1.03581910e+03\n",
      "  -3.15588527e+02 -1.57928029e+03 -1.67802068e+02 -1.30339485e+03\n",
      "  -1.89796127e+03 -1.28076694e+03 -2.01318653e+03 -5.00280055e+02\n",
      "  -9.45159323e+02 -1.67793670e+03 -1.08845833e+03 -7.81504647e+02\n",
      "  -1.40226600e+03 -9.82106612e+02 -8.57388467e+02 -7.66056099e+02\n",
      "  -6.20697591e+02 -1.30142668e+03]\n",
      " [ 6.88851085e+03  9.40667988e+03  9.56561959e+03  1.20485990e+04\n",
      "   1.53294712e+04  1.58265048e+04  1.55156401e+04  1.53533591e+04\n",
      "   1.01188757e+04  2.78593311e+03 -3.01460290e+03 -7.97173726e+03\n",
      "  -2.06460857e+04 -2.44225378e+04 -3.67651811e+04 -5.35025858e+04\n",
      "  -5.38370110e+04 -7.17016186e+04 -6.86714719e+04 -7.50201789e+04\n",
      "  -8.07430435e+04 -7.40556480e+04 -7.49726386e+04 -6.65407951e+04\n",
      "  -6.32472575e+04 -5.66131339e+04 -4.45761040e+04 -3.09632879e+04\n",
      "  -2.78098143e+04 -2.16120270e+04 -1.62254453e+04 -5.21740382e+03\n",
      "  -3.04150484e+03  5.25903414e+03  8.74332925e+03  1.14117765e+04\n",
      "   1.45281417e+04  1.69460930e+04  1.53165056e+04  1.83540964e+04\n",
      "   1.51552625e+04  2.13347436e+04  1.73400926e+04  1.70561490e+04\n",
      "   1.53356273e+04  1.68350256e+04  1.56948174e+04  1.42579750e+04\n",
      "   1.35075099e+04  1.21201148e+04]\n",
      " [ 7.06695566e+00  9.65309110e+02  7.09111404e+02  1.03775517e+03\n",
      "   4.10941918e+02  1.66670853e+03 -3.09574697e+02  3.76969785e+02\n",
      "   1.31628574e+03  2.30969613e+03  3.41128337e+02 -4.62864753e+02\n",
      "   3.31281605e+02 -2.00834150e+03 -2.07477104e+03 -3.10140103e+03\n",
      "  -3.63923894e+03 -3.96299617e+03 -8.18866545e+03 -4.50316751e+03\n",
      "  -2.36883989e+03 -5.00253320e+03 -3.94133737e+03 -3.59287239e+03\n",
      "  -3.91850529e+03 -2.77146746e+03 -2.59073240e+03 -2.76531313e+03\n",
      "  -2.45684880e+03 -2.70673568e+03 -2.05193423e+02 -4.54783937e+02\n",
      "   3.67196746e+02  2.81813813e+02  2.95859261e+02  4.09860234e+02\n",
      "   6.61761567e+02  1.25075054e+03  1.78095219e+03  3.94638672e+02\n",
      "   1.59361789e+03  5.24535198e+02  1.02691573e+03  1.00363534e+03\n",
      "   1.00100234e+03  7.48340927e+02  7.23374351e+02  5.45460558e+02\n",
      "   6.88669419e+02  5.79305906e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(dmudt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# compress all the (precompressed data) with compressor\n",
    "compressed_train = np.zeros((data_scaled.shape[0],3))\n",
    "compressed_train = np.reshape(compressed_train,newshape=(101,100,3))\n",
    "data_scaled_c    = np.reshape(data_scaled_cosmos,newshape=(101,100,3))\n",
    "data_scaled_= np.reshape(data_scaled,newshape=(101,100,50))\n",
    "# loop over cosmologies\n",
    "for ii in range(compressed_train.shape[0]):\n",
    "    for jj in range(compressed_train.shape[1]):\n",
    "        compressed_train[ii][jj] = compressor(data_scaled_[ii][jj],None)\n",
    "print(compressed_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "(51, 100, 3)\n",
      "(51, 100, 3)\n",
      "[[0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]\n",
      " [0.1 0.3 2.1]]\n"
     ]
    }
   ],
   "source": [
    "print(index)\n",
    "compressed_train1=compressed_train[0:index,:,:]\n",
    "print(compressed_train1.shape)\n",
    "compressed_train2=compressed_train[index+1:,:,:]\n",
    "compressed_data  =compressed_train[index,:,:]\n",
    "compressed_train_= np.concatenate((compressed_train1,compressed_train2))\n",
    "compressed_train_.shape, compressed_data.shape\n",
    "\n",
    "data_scaled_c1=data_scaled_c[0:index,:,:]\n",
    "print(compressed_train1.shape)\n",
    "data_scaled_c2=data_scaled_c[index+1:,:,:]\n",
    "data_scaled_c_data  =data_scaled_c[index,:,:]\n",
    "data_scaled_c_= np.concatenate((data_scaled_c1,data_scaled_c2))\n",
    "data_scaled_c_.shape, data_scaled_c_data.shape\n",
    "#print(data_scaled_c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_train_=np.reshape(compressed_train_,newshape=(-1,3))\n",
    "data_scaled_c_=np.reshape(data_scaled_c_,newshape=(-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDE estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62036 0.4159  2.9114 ] [0.     0.1841 1.2886]\n"
     ]
    }
   ],
   "source": [
    "# set up priors\n",
    "lower = np.array([np.min(data_scaled_cosmos[:,0]),np.min(data_scaled_cosmos[:,1]),np.min(data_scaled_cosmos[:,2])])\n",
    "upper = np.array([np.max(data_scaled_cosmos[:,0]),np.max(data_scaled_cosmos[:,1]),np.max(data_scaled_cosmos[:,2])])\n",
    "print(upper, lower)\n",
    "prior = priors.Uniform(lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDEs you wanna train\n",
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=3, n_data=3, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble = delfi.Delfi(compressed_data[0], prior, NDEs, \n",
    "                            Finv = Finv, \n",
    "                            theta_fiducial = theta_fiducial, \n",
    "                            param_limits = [lower, upper],\n",
    "                            param_names = ['M_\\nu', '\\Omega_m', 'A_s'], \n",
    "                            results_dir = \"./\",\n",
    "                            input_normalization=\"fisher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.load_simulations(compressed_train_,data_scaled_c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6699f64033409f8cd9dfaa8805a2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=300, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DelfiEnsemble.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.train_ndes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = DelfiEnsemble.emcee_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.triangle_plot(samples=[posterior_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python Pytorch",
   "language": "python",
   "name": "py3torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
